This is the repository for the MLMI MPhil project: Accelerating Molecular Dynamics via Neural Networks. (work still in progress)

conda activate accelmd && \
python -u main.py \
       --config configs/multi_graph_01.yaml \
       --evaluate \
       --temp-pair 0 1 \
       --checkpoint outputs/multi_graph_01/pair_0_1/models/best_model_epoch19.pt \
       --num-eval-samples 1000

conda activate accelmd && \
sbatch --export=TRAIN_MODE=single,TEMP_PAIR="0 1" \
       run_pt_swap_flows.sh

conda activate accelmd && python main.py --config configs/multi_graph_01.yaml --temp-pair 0 1 --epochs 50

Great docs of this repo: https://deepwiki.com/antoniofrancaib/accelerate-md

Toy [notebook](https://github.com/antoniofrancaib/accelerate-md/blob/main/notebooks/toy.ipynb) &nbsp; [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/antoniofrancaib/accelerate-md/blob/main/notebooks/toy.ipynb)

ğŸ§¬ Tutorial notebook to get started: (currently is quite toy, just put it here to remind me in the future to do when all the job is done!) [Introductory notebook](https://github.com/antoniofrancaib/accelerate-md/blob/main/notebooks/introduction.ipynb) &nbsp; [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/antoniofrancaib/accelerate-md/blob/main/notebooks/introduction.ipynb)

âœï¸ New to molecular simulations? Here's a curated reading + watch list for beginners: (currently is quite toy, just put it here to remind me in the future to do when all the job is done!) [RESOURCES](notebooks/RESOURCES.md)

## Problem: 
Transferable normalizing-flow swap kernels boost replica-exchange acceptance to sample Boltzmann distributions of *unseen* peptides faster than vanilla Parallel Tempering.  

## Quick start  
The pipeline I wrote is *super* user-friendly structured.

**Clone the Repository**
```bash
git clone https://github.com/your-username/accelerate-md.git
cd accelerate-md
```

**Set Up the Conda Environment**
```bash
conda env create -f environment.yml
conda activate accelmd
```

**Choose Your Experiment** 

Edit `configs/experiment.yaml` to choose your experiment type:
```yaml
experiment_type: "aldp"  # For ALDP cartesian experiments
# OR
experiment_type: "gmm"   # For Gaussian Mixture Model experiments
```

**Run the Experiment**
```bash
# Uses configs/experiment.yaml by default
sbatch run_experiment.sh

# Or run directly
python main.py --run-all --config configs/experiment.yaml
```

**Expected output structure (v0)**

Each *temperature pair* gets its own sub-directory so that checkpoints and
metrics stay neatly isolated.  For a ladder with *n* temperatures (nâˆ’1 pairs)
you will see:

```bash
outputs/<experiment_name>/
â”œâ”€â”€ used_config.yaml            # copy of the YAML used for the run (provenance)
â”œâ”€â”€ pair_0_1/                   # adjacent-pair index, not absolute Kelvin
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ best_model_epoch12.pt
â”‚   â”‚   â”œâ”€â”€ best_model_epoch26.pt
â”‚   â”‚   â””â”€â”€ â€¦ (one file per new best checkpoint)
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ swap_acceptance.json        # naÃ¯ve vs flow acceptance numbers
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ loss_curve.png              # train/val loss over epochs
â”‚       â””â”€â”€ clipping_fraction.png       # fraction of batches hitting sentinel loss
â”œâ”€â”€ pair_1_2/
â”‚   â””â”€â”€ â€¦ (same structure as above)
â”œâ”€â”€ pair_2_3/
â”‚   â””â”€â”€ â€¦
â””â”€â”€ â€¦ (nâˆ’1 directories total)
```

If you train non-adjacent pairs or use a universal flow, the directory names
will follow the same `pair_i_j` pattern but with your custom indices.

## Unified Configuration System

AccelMD uses a single configuration file for all experiments:

- **Switch experiment types** by changing `experiment_type: "aldp"` or `"gmm"`
- **Auto-generated names** like `aldp_cart_3rep_150coup_512hidden`
- **Smart defaults with overrides** - shared settings use ALDP as base, experiment-specific sections override what's different
- **Deep merging** preserves most settings while changing specifics

See `configs/README.md` for detailed configuration documentation.

## Multi-Peptide Training

AccelMD supports training flows on multiple peptides simultaneously, enabling better generalization across different molecular sizes and types.

### Configuration

Enable multi-peptide mode by setting `mode: multi` and specifying peptide lists:

```yaml
mode: multi          # Enable multi-peptide training

peptides:
  train: [AA, AK, AS]  # Peptides for training (required)
  eval:  [GA, KW]      # Peptides for evaluation (optional, defaults to train)

multi_mode:
  batching: padding    # "padding" (default) or "uniform"

model:
  architecture: transformer  # MUST be "graph" or "transformer"
```

### Key Features

- **Mixed Training**: Train one flow on multiple peptide types simultaneously
- **Separate Evaluation**: Evaluate each peptide individually with detailed metrics
- **Dimension Agnostic**: Flows handle variable molecule sizes automatically
- **Two Batching Modes**:
  - `padding`: Pad smaller molecules to batch max size (default)
  - `uniform`: Round-robin between peptide-specific batches

### Architecture Requirements

Multi-peptide mode **requires** `architecture: "graph"` or `"transformer"`. The simple architecture cannot handle variable molecule sizes.

### Output Structure

In multi-peptide mode, evaluation results are organized by peptide:

```bash
outputs/<experiment_name>/
â”œâ”€â”€ pair_0_1/
â”‚   â”œâ”€â”€ AA/                     # Per-peptide evaluation
â”‚   â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”‚   â””â”€â”€ swap_acceptance.json
â”‚   â”‚   â””â”€â”€ plots/
â”‚   â”‚       â””â”€â”€ rama_grid.png
â”‚   â”œâ”€â”€ AK/
â”‚   â”‚   â””â”€â”€ ... (same structure)
â”‚   â””â”€â”€ models/                 # Shared model checkpoints
â”‚       â””â”€â”€ best_model_epoch*.pt
```

### Example Usage

```bash
# Train on multiple peptides
conda activate accelmd && python main.py --config configs/multi_peptide_example.yaml --temp-pair 0 1

# Results saved per-peptide for detailed analysis
```

See `configs/multi_peptide_example.yaml` for a complete configuration example.

**Pipeline explained:** (this is to be improved in the future )
```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€ main.py â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  loads cfg              â”‚
â”‚  builds target          â”‚â”€â”€â–º  src/accelmd/targets/*
â”‚  builds PT sampler      â”‚
â”‚  trains flow (trainer)  â”‚â”€â”€â–º  src/accelmd/trainers/*
â”‚  runs evaluators        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
